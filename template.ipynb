{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline                                                            \n",
    "%config InlineBackend.figure_format = 'retina'  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### read csv file or files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../../../data/eco/lightning/backup_06_14_2019.gz.out.csv.gz',compression='gzip', \n",
    "                 usecols = ['SN', 'LAST_SEEN'], parse_dates=['LAST_SEEN'], dtype={'SN': str}, nrows = 100)\n",
    "\n",
    "lists = []\n",
    "path = '../../../data/eco/lightning'\n",
    "files = os.listdir(path)\n",
    "for afile in files:\n",
    "    if not os.path.isdir(afile):\n",
    "        print(afile)\n",
    "        try:\n",
    "            df0 = pd.read_csv(path + '/' + afile, compression='gzip', usecols = ['SN', 'LAST_SEEN'], dtype={'SN': str})\n",
    "        except:\n",
    "            print('error')\n",
    "            continue\n",
    "        lists.append(df0)\n",
    "df0 = pd.concat(lists)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### check basic information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "df.describe()\n",
    "df.dtypes\n",
    "df.columns\n",
    "\n",
    "df.isna().sum() # the number of NaNs for each column\n",
    "\n",
    "df.drop_duplicates(inplace = True)\n",
    "\n",
    "df[df.duplicated(subset=cols)]  # the rows with duplicated 'cols'\n",
    "\n",
    "df.loc['a', 'data']          # the cell with index 'a' at column 'data'\n",
    "\n",
    "dff.loc[dff['BAN'].isin(contact['BAN']), 'contact'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Handling Missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df[df.isnull().any(1)]  # return the data frame of all rows containing NaN(s)\n",
    "df[df['Col2'].isnull()]           # select rows with NaN in particular column?\n",
    "df.dropna(inplace = True)         #  by default, inplace = False, return a new dataframe, and df not modified.\n",
    "df.fillna('unknown', inplace = True) # fill NaN with 'unknown'\n",
    "df.fillna(0, inplace = True)         # fill NaN with 0\n",
    "df.fillna({'col1' : 0, 'col2' : -1}, inplace = True)  # fill NaN differently for each column\n",
    "df[col1].fillna(method='ffill', inplace = True)       # fill NaN with last valid value, forward fill\n",
    "df[col2].fillna(method='bfill', inplace = True)       # backward fill"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert column type and apply function on column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert Year '1985.0' to '1985'\n",
    "df['Year'] = df['Year'].astype('str')\n",
    "df['Year'] = df['Year'].apply(lambda x:x[:4] if x != 'unknown' else x) # operate on each cell of a column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### column manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Year'].unique()\n",
    "df['col'].nunique()\n",
    "\n",
    "df[df.column.isin(list)]       # all rows in df with a match in list\n",
    "df[(df.column.isin(list)) & (df[col2] > 7)]     # select rows.\n",
    "df.index \n",
    "list(df.index)  # convert index to list\n",
    "df['cumsum'] = df['sale'].cumsum()   # make a new column with cumulative sums of sales, usually first sort \n",
    "df[col].apply(lambda x:x*2)     # apply function to column, make it multiply by 2\n",
    "df.sort_values('mpg', ascending = True/False, inplace = True/False)        # order rows by values of a column\n",
    "df.rename(columns = {'y': 'year'}, inplace = True/False)        # order rows by values of a column\n",
    "df.reset_index(drop = True/False, inplace = True/False)         # reset index to DataFrame to row numbers, moving index to a new column. drop                 here means whether to drop the reset index \n",
    "df.drop(columns = ['Length', 'Height'], inplace = True/False)        # drop columns from DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0['time'] = pd.to_datetime(df0['LAST_SEEN'])\n",
    "\n",
    "df1['date'] = df1['time'].dt.date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### correlation map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrMatt = rides[['SPD', 'CLG', 'TEMP', 'DEWP', 'SLP','cnt']].corr()\n",
    "mask = np.array(corrMatt)\n",
    "mask[np.tril_indices_from(mask)] = False\n",
    "\n",
    "fig,ax= plt.subplots()\n",
    "fig.set_size_inches(20,10)\n",
    "\n",
    "sns.heatmap(corrMatt, mask=mask,vmax=.8, square=True,annot=True, annot_kws={\"size\": 20}, linewidths=1)\n",
    "ax.set_title('Correlation Heatmap', fontsize = 30)\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.melt(df, id_vars = ['Date'], value_vars=['Type', 'Value'], \n",
    "        var_name = 'Variable', value_name = 'Observations')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### group operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df0 = df.groupby('order')[\"ext price\"].sum()  # returns is not a data frame, the index now is 'order'\n",
    "df0.reset_index(inplace=True)  # now it is dataframe, reset index to DataFrame to row numbers, moving index to column 'order'\n",
    "df0 = df.groupby('order')[[\"ext price\"]].sum()  # returns a dataframe, with index 'order'\n",
    "\n",
    "df[\"Order_Total\"] = df.groupby('order')[\"ext price\"].transform('sum')\n",
    "\n",
    "aggfunc ={'a': {'percentage':lambda x: len(x[x>0])/len(x)}}\n",
    "temp.groupby('c').agg(aggfunc).reset_index()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution Plot\n",
    "sns.distplot(df.Price, ax=ax2)\n",
    "\n",
    "# Count Plot\n",
    "ax = sns.countplot(x='Year', data = df, order = sorted(df['Year'].unique()))\n",
    "# or \n",
    "sns.countplot(x='Year', data = df, order = sorted(df['Year'].unique()), ax = ax1)\n",
    "ax1 = sns.countplot(x='Genre', hue = 'Region', data = df, order = list(df['Genre'].value_counts().index))\n",
    "\n",
    "# Box Plot\n",
    "ax = sns.boxplot(x='Genre', y=\"Sales\", hue = 'Region', data=df0, palette=palette)\n",
    "# or \n",
    "ax = sns.boxplot(y=\"Sales\")\n",
    "\n",
    "# Bar Plot\n",
    "ax = sns.barplot(x='Genre', y=\"Sales\", hue = 'Region', data=df0, palette=palette)\n",
    "\n",
    "# Point Plot\n",
    "ax = sns.pointplot(x='Year', y=\"Sales\", hue = 'Region', data=df0, palette=palette)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(7,4))\n",
    "ax = sns.distplot(np.log(rides.CLG+1))\n",
    "ax.set_title(\"Log Transformed Distribution of 'CLG'\", fontsize = 16)\n",
    "ax.set_xlabel(\"Value\", fontsize = 12)\n",
    "ax.set_ylabel(\"Number of Records\", fontsize = 12)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    " # 创建1幅图 ax\n",
    "fig, ax = plt.subplots(figsize=(16,18))      \n",
    "\n",
    "# 创建2个子图x1 and ax2\n",
    "fig = plt.figure(figsize=(16,18))                       # change the figsize can make the title not overlap with the text\n",
    "\n",
    "ax1 = fig.add_subplot(121)\n",
    "ax2 = fig.add_subplot(122)                            \n",
    "             \n",
    "# apply seaborn or plt to plot data on ax1  and ax2, we can plot bar chart, boxplot, point plot…\n",
    "# details and examples are in following sections.\n",
    "\n",
    "ax1.set_title('subplot title', fontsize=16, weight='bold')\n",
    "ax1.set_xlabel('xlabel', fontsize = 14)\n",
    "ax1.set_ylabel('ylabel', fontsize = 14)\n",
    "\n",
    "plt.suptitle('Title for all subplots', fontsize=18, weight='bold')  # add the title for all subplots if there are more than 2 subplots.\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## no time order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### split data to features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['NoShow']\n",
    "features_raw = df.drop(['NoShow','PatientID','AppointmentID','ScheduledDay', 'AppointmentDay'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### log transform data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16,5))\n",
    "\n",
    "ax1 = fig.add_subplot(131)\n",
    "ax2 = fig.add_subplot(132)\n",
    "ax3 = fig.add_subplot(133)\n",
    "\n",
    "sns.set_style(\"whitegrid\")\n",
    "sns.boxplot(y=df['units'], ax=ax1)\n",
    "sns.distplot(df['units'], ax=ax2)\n",
    "sns.distplot(np.log(df['units']), ax=ax3)\n",
    "\n",
    "ax2.set(title=\"Skewed Distribution of Target Variable 'units'\")\n",
    "ax3.set(title=\"Log Transformed Distribution of Target Variable 'units'\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skewed = ['Age','WaitDay']\n",
    "features_raw[skewed] = df[skewed].apply(lambda x: np.log(x + 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import sklearn.preprocessing.StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Initialize a scaler, then apply it to the features\n",
    "scaler = MinMaxScaler()\n",
    "numerical = ['Age','WaitDay']\n",
    "features_raw[numerical] = scaler.fit_transform(df[numerical])\n",
    "\n",
    "# Show an example of a record with scaling applied\n",
    "display(features_raw.head(n = 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "quant_features = ['casual', 'registered', 'cnt', 'SPD', 'CLG', 'TEMP', 'DEWP', 'SLP']\n",
    "# Store scalings in a dictionary so we can convert back later\n",
    "scaled_features = {}\n",
    "for each in quant_features:\n",
    "    mean, std = data[each].mean(), data[each].std()\n",
    "    scaled_features[each] = [mean, std]\n",
    "    data.loc[:, each] = (data[each] - mean)/std"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### randomly split the data into training, validation, testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "# Split the 'features' and 'NoShow' data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, y, test_size = 0.2, random_state = 0)\n",
    "\n",
    "# Show the results of the split\n",
    "print (\"Training set has {} samples.\".format(X_train.shape[0]))\n",
    "print (\"Testing set has {} samples.\".format(X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building - regression metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "rfModel = RandomForestRegressor(n_estimators=100)\n",
    "rfModel.fit(X_train, y_train)\n",
    "preds_test = rfModel.predict(X_test)\n",
    "score = mean_squared_error(y_test, preds_test)\n",
    "\n",
    "print (\"MSE Value For Random Forest: \",score)\n",
    "\n",
    "\n",
    "from sklearn import linear_model\n",
    "from sklearn.linear_model import Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "regr = Ridge(alpha=1.0)\n",
    "\n",
    "regr.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions using the testing set\n",
    "y_pred = regr.predict(X_test)\n",
    "\n",
    "# The coefficients\n",
    "print('Coefficients: \\n', regr.coef_)\n",
    "# The mean squared error\n",
    "print(\"Mean squared error: %.2f\"\n",
    "      % mean_squared_error(y_test, y_pred))\n",
    "# Explained variance score: 1 is perfect prediction\n",
    "print('Variance score: %.2f' % r2_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Building - classification metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import fbeta_score, accuracy_score\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=0)\n",
    "rf_clf.fit(X_train, y_train)\n",
    "\n",
    "predictions_test = rf_clf.predict(X_test)\n",
    "# print predictions_test\n",
    "score = fbeta_score(y_test, predictions_test, beta = 1)\n",
    "print score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, roc_auc_score, precision_score, recall_score, classification_report\n",
    "\n",
    "print('the confusion matrix is')\n",
    "print(confusion_matrix(y_test, predictions_test))\n",
    "\n",
    "print('the auc-roc score is')\n",
    "print(roc_auc_score(y_test, predictions_test))\n",
    "\n",
    "print('the precision_score score is')\n",
    "print(precision_score(y_test, predictions_test))\n",
    "\n",
    "print('the recall_score score is')\n",
    "print(recall_score(y_test, predictions_test))\n",
    "\n",
    "print('the classification_report is')\n",
    "print(classification_report(y_test, predictions_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tune parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.model_selection import GridSearchCV, KFold\n",
    "from time import time\n",
    "\n",
    "n_params = { 'n_estimators':[3,5,10,50],\n",
    "              'criterion':['gini','entropy'],\n",
    "              'max_depth': [3,4,5],\n",
    "               'min_samples_split':[2,3,4,5],\n",
    "            'min_samples_leaf':[1,2],\n",
    "               'class_weight':['balanced',None]}\n",
    "\n",
    "\n",
    "scorer = make_scorer(fbeta_score, beta=1)\n",
    "\n",
    "# Perform grid search on the classifier using 'scorer' as the scoring method\n",
    "gsrf = GridSearchCV(rf_clf, n_params, cv= KFold(n_splits=5,shuffle=True), scoring=scorer)\n",
    "\n",
    "print \"start\"\n",
    "start = time() # Get start time\n",
    "\n",
    "# Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_fit = gsrf.fit(X_train, y_train)\n",
    "end = time() # Get end time\n",
    "print \"finish\"\n",
    "t_elaps = end - start\n",
    "print t_elaps\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = gsrf.best_estimator_\n",
    "\n",
    "# Make predictions using the optimized model\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "print \"\\n\"\n",
    "print \"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta = 1))\n",
    "print \"\\n\"\n",
    "print \"The optimized model is\"\n",
    "print best_clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_train_score = np.array(-gsrf.cv_results_['mean_train_score'])\n",
    "mean_train_score = mean_train_score.reshape(len(MAX_DEPTH_OPTIONS), len(n_estimators)).T\n",
    "mean_val_score = np.array(-gsrf.cv_results_['mean_test_score'])\n",
    "mean_val_score = mean_val_score.reshape(len(MAX_DEPTH_OPTIONS), len(n_estimators)).T\n",
    "\n",
    "# MAX_DEPTH_OPTIONS = [7,9,11,13,15,17,19,21]\n",
    "# n_estimators = [5,10,50,100]\n",
    "\n",
    "fig = plt.figure(figsize=(15,10))\n",
    "\n",
    "for i, n in enumerate(n_estimators):\n",
    "    ax = fig.add_subplot(2, 2, i+1)\n",
    "    ax.plot(np.array(MAX_DEPTH_OPTIONS), mean_train_score[i], 'o-', color=\"r\",\n",
    "             label=\"Training error\")\n",
    "    ax.plot(np.array(MAX_DEPTH_OPTIONS), mean_val_score[i], 'o-', color=\"g\",\n",
    "             label=\"Validation error\")\n",
    "    ax.xaxis.set(ticks=MAX_DEPTH_OPTIONS)\n",
    "    ax.set_title(\"n_estimators = '%d'\"%(n), fontsize = 14)\n",
    "    ax.legend(loc=\"best\")\n",
    "    ax.set_xlabel('Max Depth')\n",
    "    ax.set_ylabel('Mean Squared Error')\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature importance for random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importances = pd.DataFrame(rfModel.feature_importances_,\n",
    "                                   index = train_features.columns,\n",
    "                                    columns=['importance']).sort_values('importance',ascending=False)\n",
    "feature_importances.index.name='feature'\n",
    "feature_importances.reset_index(inplace = True)\n",
    "feature_importances.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## time order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = data[data['date'] == 28]\n",
    "test_data = data[-31*24:]\n",
    "\n",
    "# Hold out the last 5 days or so of the remaining data as a validation set\n",
    "val_data = data[data['date'].isin([23,24,25,26,27])]\n",
    "\n",
    "# Remove the test and validation data from the orginial data set \n",
    "train_data = data[data['date'] < 23]\n",
    "\n",
    "# Separate the data into features and targets\n",
    "target_fields = ['units']\n",
    "train_features, train_targets = train_data.drop(target_fields, axis=1), train_data[target_fields]\n",
    "val_features, val_targets = val_data.drop(target_fields, axis=1), val_data[target_fields]\n",
    "test_features, test_targets = test_data.drop(target_fields, axis=1), test_data[target_fields]\n",
    "\n",
    "X_train = np.array(train_features)\n",
    "y_train = np.array(train_targets['cnt'])\n",
    "X_val = np.array(val_features)\n",
    "y_val = np.array(val_targets['cnt'])\n",
    "X_test = np.array(test_features)\n",
    "y_test = np.array(test_targets['cnt'])\n",
    "\n",
    "print(X_train.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### tune max depth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, PredefinedSplit\n",
    "from time import time\n",
    "\n",
    "MAX_DEPTH_OPTIONS = [11,13,15,17,19,21,23,25,27,29]\n",
    "num_estimators = [5,10,50,100]\n",
    "\n",
    "n_params = {'n_estimators':num_estimators,\n",
    "            'max_depth': MAX_DEPTH_OPTIONS}\n",
    "\n",
    "my_validation_fold = []\n",
    "\n",
    "for i in range(len(X_train)):\n",
    "    my_validation_fold.append(-1)\n",
    "\n",
    "for i in range(len(X_val)):\n",
    "    my_validation_fold.append(0)\n",
    "\n",
    "# Perform grid search on the classifier using 'scorer' as the scoring method\n",
    "gsrf = GridSearchCV(rfModel, n_params, cv= PredefinedSplit(test_fold=my_validation_fold), \n",
    "                    scoring='neg_mean_squared_error')\n",
    "# gsrf = GridSearchCV(rfModel, n_params, cv= 3, \n",
    "#                     scoring='neg_mean_squared_error')\n",
    "\n",
    "print(\"start\")\n",
    "start = time() # Get start time\n",
    "\n",
    "# Fit the grid search object to the training data and find the optimal parameters\n",
    "grid_fit = gsrf.fit(np.append(X_train,X_val,axis=0), np.append(y_train,y_val,axis=0))\n",
    "end = time() # Get end time\n",
    "print(\"finish\")\n",
    "t_elaps = end - start\n",
    "print(t_elaps)\n",
    "\n",
    "# Get the estimator\n",
    "best_clf = gsrf.best_estimator_\n",
    "\n",
    "# Make predictions using the optimized model\n",
    "best_predictions = best_clf.predict(X_test)\n",
    "print(\"\\n\")\n",
    "print(\"Final score on the testing data: {:.4f}\".format(MSE(y_test, best_predictions)))\n",
    "print(\"\\n\")\n",
    "print(\"The optimized model is\")\n",
    "print(best_clf)\n",
    "print(\"\\n\")\n",
    "print(\"The best score on the validation set is:\")\n",
    "print(gsrf.best_score_)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
